{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPg7i1t18Yu5lsSRI23FQb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miragecore/SandBox/blob/devel/Colab/Stitch/WebLiveStich.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opencv Video Steam using FastAPI\n",
        "\n",
        "참조 1 Flask, Opencv 스트리밍 서버  \n",
        "https://pyimagesearch.com/2019/09/02/opencv-stream-video-to-web-browser-html-page/\n",
        "\n",
        "참조 2  Flask -> fastAPI  \n",
        "https://testdriven.io/blog/moving-from-flask-to-fastapi/\n",
        "\n",
        "참조 3 rtsp 스트리밍  \n",
        "https://github.com/mpimentel04/rtsp_fastapi"
      ],
      "metadata": {
        "id": "NxpZdRVgURWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi"
      ],
      "metadata": {
        "id": "hE-FR-GcVOhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!pip install uvicorn"
      ],
      "metadata": {
        "id": "7FuwcQ77xfjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ngrok Auth\n",
        "!mkdir -p /drive/ngrok-ssh\n",
        "%cd /drive/ngrok-ssh\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip -O ngrok-stable-linux-amd64.zip\n",
        "!unzip -u ngrok-stable-linux-amd64.zip\n",
        "!cp /drive/ngrok-ssh/ngrok /ngrok\n",
        "!chmod +x /ngrok\n",
        "\n",
        "!/ngrok authtoken \"24hROn7coCpNvy220TtwTSP0aYA_3ZaXPFsPZy4FprkJNwR35\""
      ],
      "metadata": {
        "id": "5ocLWn69zXY7",
        "outputId": "bb76939e-6391-4375-9462-aced0f869df0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/drive/ngrok-ssh\n",
            "--2022-02-21 14:40:51--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 54.161.241.46, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  34.0MB/s    in 0.4s    \n",
            "\n",
            "2022-02-21 14:40:52 (34.0 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imutils\n",
        "import cv2\n",
        "from imutils.video import VideoStream\n",
        "import threading\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#SIFT or SURF는 4.3이상의 버전에서만 사용가능하다. \n",
        "if cv2.__version__ != \"4.4.0\":\n",
        "  print(cv2.__version__)\n",
        "  #설치후에는 런타임을 재시작해줘야 한다.\n",
        "  !pip install opencv-contrib-python==4.4.0.44"
      ],
      "metadata": {
        "id": "phan9eGyU3ey"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BiBEJu8DUQ57",
        "outputId": "068b6bc9-95a1-4b99-f0f6-5daae77e7482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#스틸컷에 쓸 이미지 로딩을 위한 구글드라이브 마운트\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class FrameGenerator:\n",
        "    def __init__(self, img, roih, roiw, frameCount = 50):\n",
        "        self.source = img\n",
        "        self.roih = roih\n",
        "        self.roiw = roiw\n",
        "        self.source_h, self.source_w = img.shape[:2]\n",
        "        #h, w\n",
        "        self.maxStride = [round(roih/3), round(roiw/3)]\n",
        "        self.frameCount = frameCount\n",
        "       \n",
        "        img_h, img_w = img.shape[:2]\n",
        "        sx = random.randint(0, img_w-roiw)\n",
        "        sy = random.randint(0, img_h-roih)\n",
        "        self.img_h = img_h\n",
        "        self.img_w = img_w\n",
        "\n",
        "        self.frame = source[sy:sy+roih, sx:sx+roiw]\n",
        "        self.sx = sx\n",
        "        self.sy = sy\n",
        "\n",
        "    def getNextPoint(self):\n",
        "        sx = random.randint(self.sx - self.maxStride[0],\\\n",
        "                self.sx + self.maxStride[0])\n",
        "        sy = random.randint(self.sy - self.maxStride[1],\\\n",
        "                self.sy + self.maxStride[1])\n",
        "       \n",
        "        if sx + self.roiw > self.img_w:\n",
        "            sx = self.img_w - self.roiw\n",
        "       \n",
        "        if sx < 0:\n",
        "            sx = 0\n",
        "       \n",
        "        if sy + self.roih > self.img_h:\n",
        "            sy = self.img_h - self.roih\n",
        "        \n",
        "        if sy < 0:\n",
        "            sy = 0\n",
        "\n",
        "        return sx, sy\n",
        "\n",
        "    def generate(self):\n",
        "        sx, sy = self.getNextPoint()\n",
        "\n",
        "        self.frame = source[sy:sy+self.roih,\\\n",
        "                      sx:sx+self.roiw]\n",
        "\n",
        "        self.sx = sx\n",
        "        self.sy = sy\n",
        "        self.frameCount -= 1\n",
        "\n",
        "        return self.frame"
      ],
      "metadata": {
        "id": "8ZvS3ZIGnVUN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image의 외곽 좌표를 np.array로 리턴\n",
        "def getImageCorner(img):\n",
        "  h, w = img.shape[:2]\n",
        "  return np.float32([ [0,0],[0,h],[w,h],[w,0]])"
      ],
      "metadata": {
        "id": "Jv6pHUlUq9yQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 이미지의 그레이 이미지 복사본을 리턴\n",
        "def getGrayImage(img):\n",
        "  if len(img.shape) > 2:\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  else :\n",
        "    return img.copy()"
      ],
      "metadata": {
        "id": "dqsEPSu4q-bE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dst의 roi 영역에 src 이미지를 설정\n",
        "def copyImageROI(src, dst, x, y):\n",
        "  h,w = src.shape[:2]\n",
        "  #assert dst.shape[0] < y+h, \"src size error\"\n",
        "  #assert dst.shape[1] < x+w, \"src size error\"\n",
        "\n",
        "  dst[y:y+h, x: x+w] = src"
      ],
      "metadata": {
        "id": "YtpEKB0SrBtO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTfCorner(c1, c2):\n",
        "  corner = np.concatenate((c1, c2), axis=0)\n",
        "  [xmin, ymin] = np.int32(corner.min(axis=0).ravel())\n",
        "  [xmax, ymax] = np.int32(corner.max(axis=0).ravel())\n",
        "  return xmax, xmin, ymax, ymin"
      ],
      "metadata": {
        "id": "KMz8bYoqrEFU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FrameStitcher:\n",
        "  def __init__(self, w, h):\n",
        "    #ORB Dector init   \n",
        "    #self.detector= cv2.ORB_create()\n",
        "    self.detector = cv2.SIFT_create()\n",
        "\n",
        "    #FLANN Matcher init\n",
        "    #ORB\n",
        "    #FLANN_INDEX_LSH = 6\n",
        "    #index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12,\\\n",
        "    #                    multi_probe_level=1)\n",
        "\n",
        "    #SIFT\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "    search_params = dict(checks = 50)\n",
        "\n",
        "    self.matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    #최종 ROI 좌표\n",
        "    self.current_roi = []\n",
        "    \n",
        "    #최소 매칭 수\n",
        "    self.MIN_MATCH_COUNT = 4\n",
        "\n",
        "    #현재 프레임 카운트\n",
        "    self.frame_count = 0\n",
        "\n",
        "    #최종 결과 이미지의 크기 설정 및 초기화\n",
        "    self.output_frame_w = w\n",
        "    self.output_frame_h = h\n",
        "    self.outputframe = np.zeros((h,w,3), np.uint8)\n",
        "    \n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    self.kernel = (kernel == 1).astype('uint8')\n",
        "\n",
        "    #변환 변수들 0 초기화\n",
        "    #입력 프레임 크기\n",
        "    self.frame_w = 0\n",
        "    self.frame_h = 0\n",
        "\n",
        "    #입력 프레임 코너 좌표\n",
        "    self.frame_corner = []\n",
        "    \n",
        "    #마지막 변환 매트릭스\n",
        "    self.M = np.array([[1,0,0], [0,1,0], [0,0,1]],np.float32)\n",
        "\n",
        "    #마지막 프레임 keypoint, descriptor\n",
        "    self.kp = None\n",
        "    self.desc = None\n",
        "\n",
        "  def initFirstFrame(self, frame):\n",
        "    #카메라 프레임은 항상 동일한 크기로 가정\n",
        "    self.frame_h, self.frame_w = frame.shape[:2]\n",
        "    #동일한 영상이면 매 프레임마다 최외곽 좌표도 동일함\n",
        "    self.frame_corner = getImageCorner(frame).reshape(-1,1,2)\n",
        "    \n",
        "    #화면 중앙으로 보내기 위한 변환 매트릭스 생성\n",
        "    tx = round(self.output_frame_w /2 - self.frame_w /2)\n",
        "    ty = round(self.output_frame_h/2 - self.frame_h /2)\n",
        "    self.M = np.array([[1,0,tx],[0,1,ty],[0,0,1]],np.float32)\n",
        "    \n",
        "    kp, desc = self.findFeature(frame)\n",
        "    self.kp = kp\n",
        "    self.desc = desc\n",
        "\n",
        "    #평행이동이라 계산 불필요\n",
        "    #img1_tf_corner = cv2.perspectiveTransform(self.frame_corner, self.M)\n",
        "    #초기 변환으로 첫 프레임을 결과 영상 센터로 이동 \n",
        "    #tmp_frame = cv2.warpPerspective(frame,self.M,(self.frame_w, self.frame_h))\n",
        "\n",
        "    #출력 프레임 roi에 이미지 설정\n",
        "    copyImageROI(frame, self.outputframe, tx,ty)\n",
        "    #초기 출력 영역 마스크 생성\n",
        "    _, self.outputmask = cv2.threshold(self.outputframe, 0, 255, \\\n",
        "                                       cv2.THRESH_BINARY)\n",
        "    \n",
        "    #outputframe에서 마지막 추가된 프레임만의 영역\n",
        "    self.current_roi = [tx, ty, self.frame_w, self.frame_h]\n",
        "    self.frame_count += 1\n",
        "\n",
        "    #cv2_imshow(self.outputframe)\n",
        "    \n",
        "  def setFrame(self, frame):\n",
        "    #한번 실행되고 매번 검사하는 것은 고민해볼 문제\n",
        "    if self.frame_count == 0:\n",
        "      self.initFirstFrame(frame)\n",
        "\n",
        "    kp1, desc1 = self.findFeature(frame)\n",
        "\n",
        "    #print(desc1)\n",
        "    #print(self.desc)\n",
        "    good = self.findGoodMatch(desc1, self.desc)\n",
        "\n",
        "    if len(good) < self.MIN_MATCH_COUNT:\n",
        "      return self.outputframe\n",
        "\n",
        "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ])\\\n",
        "    .reshape(-1,1,2)\n",
        "    dst_pts = np.float32([ self.kp[m.trainIdx].pt for m in good ])\\\n",
        "    .reshape(-1,1,2)\n",
        "\n",
        "    #frame을 outputframe으로 변환 할 것이기 때문에\n",
        "    tM, RANSAC_mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
        "\n",
        "    #외곽 좌표 변환\n",
        "    corner = getImageCorner(frame).reshape(-1,1,2)  \n",
        "    frame_tf_corner = cv2.perspectiveTransform(corner,tM)\n",
        "    xmax, xmin, ymax, ymin = getTfCorner(self.frame_corner,frame_tf_corner)\n",
        "\n",
        "    #새로운 ROI 설정\n",
        "    roix = self.current_roi[0] + xmin\n",
        "    roiy = self.current_roi[1] + ymin\n",
        "    roiw = xmax - xmin\n",
        "    roih = ymax - ymin\n",
        "\n",
        "    #새로운 프레임의 시작 지점으로 ROI 시작 이동\n",
        "    self.current_roi[0] += round(frame_tf_corner[0][0][0])\n",
        "    self.current_roi[1] += round(frame_tf_corner[0][0][1])\n",
        "\n",
        "    source_roi = self.outputframe[roiy:roiy+roih, roix:roix+roiw]\n",
        "    #cv2_imshow(source_roi)\n",
        "\n",
        "    #영상 변환 & 마스크 생성\n",
        "    warp_img = cv2.warpPerspective(frame,tM,(roiw, roih))\n",
        "    wg = getGrayImage(warp_img)\n",
        "    _, warp_mask = cv2.threshold(wg, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    #Result Mask 기반 합성으로 변경 필요 - 겹치지 않는 영역이 생기지 않게\n",
        "    warp_mask = cv2.erode(warp_mask, self.kernel, borderType=cv2.BORDER_CONSTANT)\n",
        "    ### 새로운 이미지 전체가 반영되도록 병합\n",
        "    warp_mask_inv = cv2.bitwise_not(warp_mask)\n",
        "\n",
        "    masked_fg = cv2.bitwise_and(warp_img, warp_img, mask=warp_mask)\n",
        "    masked_bg = cv2.bitwise_and(source_roi, source_roi, mask=warp_mask_inv)\n",
        "    added = masked_fg + masked_bg\n",
        "\n",
        "    #cv2_imshow(added)\n",
        "    self.outputframe[roiy:roiy+roih, roix:roix+roiw] = added\n",
        "\n",
        "    #마지막 프레임 keypoint & descriptor update\n",
        "    self.last_frame = frame\n",
        "    self.kp = kp1\n",
        "    self.desc = desc1\n",
        "    self.frame_count += 1\n",
        "\n",
        "    return self.outputframe\n",
        "\n",
        "  #2장의 이미지를 입력 받아서 keypoint와 변환 매트릭스를 리턴\n",
        "  def findFeature(self, img,detector_type = 'SIFT', mask_enable=False,\\\n",
        "                min_match_count = 10):\n",
        "    #흑백 이미지 생성\n",
        "    img_gray = getGrayImage(img)\n",
        "\n",
        "    #이미지에서 0인 영역으로 마스크를 생성시켜 계산의 속도 향상, \n",
        "    #검은 영역이 없다면 무쓸모\n",
        "    mask = None\n",
        "    if(mask_enable):\n",
        "      _, mask = cv2.threshold(img_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "    \n",
        "    #keypoint와 Descriptor 찾기\n",
        "    kp, desc = self.detector.detectAndCompute(img, mask)\n",
        "\n",
        "    return kp, desc\n",
        "\n",
        "  #Descriptor를 비교하여 매치 상태가 좋은 점들만 리턴\n",
        "  def findGoodMatch(self, desc1, desc2, \\\n",
        "                     matcher_type = 'FLANN', \\\n",
        "                     best_match_count = 2, \\\n",
        "                     match_dist = 0.7): \n",
        "    matches = self.matcher.knnMatch(desc1,desc2,k=best_match_count)\n",
        "\n",
        "    good = []\n",
        "    for m_n in matches:\n",
        "      if len(m_n) != 2:\n",
        "        continue\n",
        "      (m,n) = m_n\n",
        "      if m.distance < match_dist *n.distance:\n",
        "          good.append(m)\n",
        "    return good\n"
      ],
      "metadata": {
        "id": "o8p9FitPrGlM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#드라이브안에서 프로젝트 드라이브로 이동\n",
        "root_path = '/content/drive/MyDrive/SandBox/Stitch'\n",
        "\n",
        "os.chdir(root_path);\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "source = cv2.imread('staringNight.png')\n",
        "\n",
        "frameGen = FrameGenerator(source, 300, 300)\n",
        "h,w = source.shape[:2]\n",
        "fs = FrameStitcher(w,h)\n",
        "fs.initFirstFrame(frameGen.generate())\n"
      ],
      "metadata": {
        "id": "6Hlrn32BUtTA",
        "outputId": "c2bbc6a1-dca1-4414-cdcb-472b461bc5fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SandBox/Stitch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sourceframe = None\n",
        "outputframe = None\n",
        "outputlock = threading.Lock()\n",
        "sourcelock = threading.Lock()\n",
        "#vs = VideoStream(src=0).start()\n",
        "\n",
        "def generate_frame():\n",
        "  global outputframe, sourceframe,  outputlock, sourcelock\n",
        "\n",
        "  i = 0;\n",
        "  while True:\n",
        "    #다른 사진으로 프레임 변경\n",
        "    source = frameGen.generate()\n",
        "    frame = fs.setFrame(source)\n",
        "\n",
        "    with sourcelock:\n",
        "      sourceframe = source.copy()\n",
        "\n",
        "    with outputlock:\n",
        "      outputframe = frame.copy()\n",
        "    #FPS를 1로\n",
        "    time.sleep(1)\n",
        "    "
      ],
      "metadata": {
        "id": "UgsbKkd6r72t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateOutput():\n",
        "  global outputframe, outputlock\n",
        "\n",
        "  while True:\n",
        "    with outputlock:\n",
        "      if outputframe is None:\n",
        "        continue\n",
        "\n",
        "      (flag, encodedImage) = cv2.imencode(\".jpg\", outputframe)\n",
        "      outputframe = None\n",
        "\n",
        "      if flag is None:\n",
        "        continue\n",
        "\n",
        "    yield(b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' +\n",
        "\t\t\t  bytearray(encodedImage) + b'\\r\\n')"
      ],
      "metadata": {
        "id": "IKqbb6R3traC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateSource():\n",
        "  global sourceframe, sourcelock\n",
        "\n",
        "  while True:\n",
        "    with sourcelock:\n",
        "      if sourceframe is None:\n",
        "        continue\n",
        "\n",
        "      (flag, encodedImage) = cv2.imencode(\".jpg\", sourceframe)\n",
        "      sourceframe = None\n",
        "\n",
        "      if flag is None:\n",
        "        continue\n",
        "\n",
        "    yield(b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' +\n",
        "\t\t\t  bytearray(encodedImage) + b'\\r\\n')"
      ],
      "metadata": {
        "id": "lpaUh4ybsulQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.responses import StreamingResponse, HTMLResponse"
      ],
      "metadata": {
        "id": "rI0ha_s4U5Z9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI(title='Opencv Streaming')\n",
        "\n",
        "@app.get(\"/\",response_class=HTMLResponse)\n",
        "async def home():\n",
        "  return \"\"\"\n",
        "  <html>\n",
        "  <head>\n",
        "    <title>Image Files Streaming</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <h1>Image File Streaming</h1>\n",
        "    <img src=\"/video_source\">\n",
        "    <img src=\"/video_pano\" width=\"800\" height=\"600\">\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.get(\"/video_source\")\n",
        "def video_source():\n",
        "\t# return the response generated along with the specific media\n",
        "\t# type (media_type)\n",
        "\treturn StreamingResponse(generateSource(),media_type=\"multipart/x-mixed-replace;boundary=frame\")\n",
        " \n",
        "@app.get(\"/video_pano\")\n",
        "def video_pano():\n",
        "\t# return the response generated along with the specific media\n",
        "\t# type (media_type)\n",
        "\treturn StreamingResponse(generateOutput(),media_type=\"multipart/x-mixed-replace;boundary=frame\")"
      ],
      "metadata": {
        "id": "b5ApkUXfVKk5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start frame generate thread\n",
        "t = threading.Thread(target=generate_frame,args=())\n",
        "t.daemon = True\n",
        "t.start()"
      ],
      "metadata": {
        "id": "VTuimAZj1I7p"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Allows the server to be run in this interactive environment\n",
        "#nest_asyncio.apply()\n",
        "\n",
        "# Host depends on the setup you selected (docker or virtual env)\n",
        "#host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n",
        "\n",
        "# Spin up the server!    \n",
        "#uvicorn.run(app, host=host, port=8000)\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "id": "lteqMRM1xd_F",
        "outputId": "40705d4a-3ab8-4ff5-c96d-4735686f06a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: http://09a3-35-186-178-96.ngrok.io\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1112]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     14.35.26.238:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     14.35.26.238:0 - \"GET /video_source HTTP/1.1\" 200 OK\n",
            "INFO:     14.35.26.238:0 - \"GET /video_pano HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for background tasks to complete. (CTRL+C to force quit)\n",
            "INFO:     Finished server process [1112]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TL4pBeGXvemm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}