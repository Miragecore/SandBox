{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPggbURjwdocvbC2xLMwra5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miragecore/SandBox/blob/devel/Colab/Stitch/WebLiveStich.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opencv Video Steam using FastAPI\n",
        "\n",
        "참조 1 Flask, Opencv 스트리밍 서버  \n",
        "https://pyimagesearch.com/2019/09/02/opencv-stream-video-to-web-browser-html-page/\n",
        "\n",
        "참조 2  Flask -> fastAPI  \n",
        "https://testdriven.io/blog/moving-from-flask-to-fastapi/\n",
        "\n",
        "참조 3 rtsp 스트리밍  \n",
        "https://github.com/mpimentel04/rtsp_fastapi"
      ],
      "metadata": {
        "id": "NxpZdRVgURWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "#SIFT or SURF는 4.3이상의 버전에서만 사용가능하다. \n",
        "if cv2.__version__ != \"4.4.0\":\n",
        "  print(cv2.__version__)\n",
        "  #설치후에는 런타임을 재시작해줘야 한다.\n",
        "  !pip install opencv-contrib-python==4.4.0.44"
      ],
      "metadata": {
        "id": "sl0L3lK5jNWq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi\n",
        "!pip install pyngrok\n",
        "!pip install uvicorn"
      ],
      "metadata": {
        "id": "hE-FR-GcVOhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ngrok Auth\n",
        "!mkdir -p /drive/ngrok-ssh\n",
        "%cd /drive/ngrok-ssh\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip -O ngrok-stable-linux-amd64.zip\n",
        "!unzip -u ngrok-stable-linux-amd64.zip\n",
        "!cp /drive/ngrok-ssh/ngrok /ngrok\n",
        "!chmod +x /ngrok\n",
        "\n",
        "!/ngrok authtoken \"24hROn7coCpNvy220TtwTSP0aYA_3ZaXPFsPZy4FprkJNwR35\""
      ],
      "metadata": {
        "id": "5ocLWn69zXY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imutils\n",
        "from imutils.video import VideoStream\n",
        "import threading\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "metadata": {
        "id": "phan9eGyU3ey"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BiBEJu8DUQ57",
        "outputId": "c5e995d8-1517-4e33-fa5e-ed1f0370c4e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#스틸컷에 쓸 이미지 로딩을 위한 구글드라이브 마운트\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class FrameGenerator:\n",
        "    def __init__(self, img, roih, roiw):\n",
        "        self.source = img\n",
        "        self.roih = roih\n",
        "        self.roiw = roiw\n",
        "        self.source_h, self.source_w = img.shape[:2]\n",
        "        #h, w\n",
        "        self.maxStride = [round(roih/3), round(roiw/3)]\n",
        "       \n",
        "        img_h, img_w = img.shape[:2]\n",
        "        sx = random.randint(0, img_w-roiw)\n",
        "        sy = random.randint(0, img_h-roih)\n",
        "        self.img_h = img_h\n",
        "        self.img_w = img_w\n",
        "\n",
        "        self.frame = source[sy:sy+roih, sx:sx+roiw]\n",
        "        self.sx = sx\n",
        "        self.sy = sy\n",
        "\n",
        "    def getNextPoint(self):\n",
        "        sx = random.randint(self.sx - self.maxStride[0],\\\n",
        "                self.sx + self.maxStride[0])\n",
        "        sy = random.randint(self.sy - self.maxStride[1],\\\n",
        "                self.sy + self.maxStride[1])\n",
        "       \n",
        "        if sx + self.roiw > self.img_w:\n",
        "            sx = self.img_w - self.roiw\n",
        "       \n",
        "        if sx < 0:\n",
        "            sx = 0\n",
        "       \n",
        "        if sy + self.roih > self.img_h:\n",
        "            sy = self.img_h - self.roih\n",
        "        \n",
        "        if sy < 0:\n",
        "            sy = 0\n",
        "\n",
        "        return sx, sy\n",
        "\n",
        "    def generate(self):\n",
        "        sx, sy = self.getNextPoint()\n",
        "\n",
        "        self.frame = source[sy:sy+self.roih,\\\n",
        "                      sx:sx+self.roiw]\n",
        "\n",
        "        self.sx = sx\n",
        "        self.sy = sy\n",
        "\n",
        "        print('eng')\n",
        "\n",
        "        return self.frame"
      ],
      "metadata": {
        "id": "8ZvS3ZIGnVUN"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image의 외곽 좌표를 np.array로 리턴\n",
        "def getImageCorner(img):\n",
        "  h, w = img.shape[:2]\n",
        "  return np.float32([ [0,0],[0,h],[w,h],[w,0]])"
      ],
      "metadata": {
        "id": "Jv6pHUlUq9yQ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 이미지의 그레이 이미지 복사본을 리턴\n",
        "def getGrayImage(img):\n",
        "  if len(img.shape) > 2:\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  else :\n",
        "    return img.copy()"
      ],
      "metadata": {
        "id": "dqsEPSu4q-bE"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dst의 roi 영역에 src 이미지를 설정\n",
        "def copyImageROI(src, dst, x, y):\n",
        "  h,w = src.shape[:2]\n",
        "  #assert dst.shape[0] < y+h, \"src size error\"\n",
        "  #assert dst.shape[1] < x+w, \"src size error\"\n",
        "\n",
        "  dst[y:y+h, x: x+w] = src"
      ],
      "metadata": {
        "id": "YtpEKB0SrBtO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTfCorner(c1, c2):\n",
        "  corner = np.concatenate((c1, c2), axis=0)\n",
        "  [xmin, ymin] = np.int32(corner.min(axis=0).ravel())\n",
        "  [xmax, ymax] = np.int32(corner.max(axis=0).ravel())\n",
        "  return xmax, xmin, ymax, ymin"
      ],
      "metadata": {
        "id": "KMz8bYoqrEFU"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FrameStitcher:\n",
        "  def __init__(self, w, h):\n",
        "    #ORB Dector init   \n",
        "    #self.detector= cv2.ORB_create()\n",
        "    self.detector = cv2.SIFT_create()\n",
        "\n",
        "    #FLANN Matcher init\n",
        "    #When ORB\n",
        "    #FLANN_INDEX_LSH = 6\n",
        "    #index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12,\\\n",
        "    #                    multi_probe_level=1)\n",
        "\n",
        "    #SIFT\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "    search_params = dict(checks = 50)\n",
        "\n",
        "    self.matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    \n",
        "    #최소 매칭 수\n",
        "    self.MIN_MATCH_COUNT = 4\n",
        "\n",
        "    #현재 프레임 카운트\n",
        "    self.frame_count = 0\n",
        "\n",
        "    #최종 결과 이미지의 크기 설정 및 초기화\n",
        "    self.output_frame_w = w\n",
        "    self.output_frame_h = h\n",
        "    self.outputframe = np.zeros((h,w,3), np.uint8)\n",
        "    \n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    self.kernel = (kernel == 1).astype('uint8')\n",
        "\n",
        "    self.last_roi = []\n",
        "\n",
        "    #마지막 프레임 keypoint, descriptor\n",
        "    self.kp = None\n",
        "    self.desc = None\n",
        "\n",
        "  def initFirstFrame(self, frame):\n",
        "    #카메라 프레임은 항상 동일한 크기로 가정\n",
        "    self.frame_h, self.frame_w = frame.shape[:2]\n",
        "    #동일한 영상이면 매 프레임마다 최외곽 좌표도 동일함\n",
        "    self.last_frame_corner = getImageCorner(frame).reshape(-1,1,2)\n",
        "    \n",
        "    #화면 중앙으로 보내기 위한 변환 매트릭스 생성\n",
        "    tx = round(self.output_frame_w /2 - self.frame_w /2)\n",
        "    ty = round(self.output_frame_h/2 - self.frame_h /2)\n",
        "    self.M = np.array([[1,0,tx],[0,1,ty],[0,0,1]],np.float32)\n",
        "    \n",
        "    kp, desc = self.findFeature(frame)\n",
        "\n",
        "    self.kp = kp\n",
        "    self.desc = desc\n",
        "\n",
        "    #계산이 필요없긴 하다.\n",
        "    self.last_roi = cv2.perspectiveTransform(self.last_frame_corner, self.M)\n",
        "    copyImageROI(frame, self.outputframe, tx,ty)\n",
        "    self.frame_count += 1\n",
        "\n",
        "    #cv2_imshow(self.outputframe)\n",
        "    \n",
        "  def setFrame(self, frame):\n",
        "    #한번 실행되고 매번 검사하는 것은 고민해볼 문제\n",
        "    if self.frame_count == 0:\n",
        "      self.initFirstFrame(frame)\n",
        "      return self.outputframe\n",
        "\n",
        "    kp1, desc1 = self.findFeature(frame)\n",
        "\n",
        "    #print(desc1)\n",
        "    #print(self.desc)\n",
        "    good = self.findGoodMatch(desc1, self.desc)\n",
        "\n",
        "    if len(good) < self.MIN_MATCH_COUNT:\n",
        "      return self.outputframe\n",
        "\n",
        "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ])\\\n",
        "    .reshape(-1,1,2)\n",
        "    dst_pts = np.float32([ self.kp[m.trainIdx].pt for m in good ])\\\n",
        "    .reshape(-1,1,2)\n",
        "\n",
        "    #frame을 outputframe으로 변환 할 것이기 때문에\n",
        "    H, RANSAC_mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
        "\n",
        "    #외곽 좌표 변환\n",
        "    corner = getImageCorner(frame).reshape(-1,1,2)  \n",
        "    tf_corner = cv2.perspectiveTransform(corner,H)\n",
        "    xmax, xmin, ymax, ymin = getTfCorner(self.last_frame_corner,tf_corner)\n",
        "\n",
        "    t = [-xmin,-ymin]\n",
        "    Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
        "    Ht = Ht.dot(H)\n",
        "    \n",
        "    roix = round(self.last_roi[0][0][0] +xmin)\n",
        "    roiy = round(self.last_roi[0][0][1] +ymin)\n",
        "    roiw = xmax - xmin\n",
        "    roih = ymax - ymin\n",
        "\n",
        "    source_roi = self.outputframe[roiy:roiy+roih, roix:roix+roiw]\n",
        "    \n",
        "    #영상 변환 & 마스크 생성\n",
        "    warp_img = cv2.warpPerspective(frame,Ht,(xmax - xmin, ymax- ymin))\n",
        "    wg = getGrayImage(warp_img)\n",
        "    _, warp_mask = cv2.threshold(wg, 0, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    #Result Mask 기반 합성으로 변경 필요 - 겹치지 않는 영역이 생기지 않게\n",
        "    warp_mask = cv2.erode(warp_mask, self.kernel, borderType=cv2.BORDER_CONSTANT)\n",
        "    ### 새로운 이미지 전체가 반영되도록 병합\n",
        "    warp_mask_inv = cv2.bitwise_not(warp_mask)\n",
        "\n",
        "    masked_fg = cv2.bitwise_and(warp_img, warp_img, mask=warp_mask)\n",
        "    masked_bg = cv2.bitwise_and(source_roi, source_roi, mask=warp_mask_inv)\n",
        "    added = masked_fg + masked_bg\n",
        "\n",
        "    #cv2_imshow(added)\n",
        "    self.outputframe[roiy:roiy+roih, roix:roix+roiw] = added\n",
        "\n",
        "    #마지막 프레임 keypoint & descriptor update   \n",
        "    #roi update\n",
        "    self.last_frame_corner = getImageCorner(frame).reshape(-1,1,2)\n",
        "    \n",
        "    self.last_roi[0][0][0] += tf_corner[0][0][0]\n",
        "    self.last_roi[0][0][1] += tf_corner[0][0][1]\n",
        "    \n",
        "    self.last_frame = frame\n",
        "    self.kp = kp1\n",
        "    self.desc = desc1\n",
        "    self.frame_count += 1\n",
        "\n",
        "    return self.outputframe\n",
        "\n",
        "  #2장의 이미지를 입력 받아서 keypoint와 변환 매트릭스를 리턴\n",
        "  def findFeature(self, img,detector_type = 'SIFT', mask_enable=False,\\\n",
        "                min_match_count = 10):\n",
        "    #흑백 이미지 생성\n",
        "    img_gray = getGrayImage(img)\n",
        "\n",
        "    #이미지에서 0인 영역으로 마스크를 생성시켜 계산의 속도 향상, \n",
        "    #검은 영역이 없다면 무쓸모\n",
        "    mask = None\n",
        "    if(mask_enable):\n",
        "      _, mask = cv2.threshold(img_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "    \n",
        "    #keypoint와 Descriptor 찾기\n",
        "    kp, desc = self.detector.detectAndCompute(img, mask)\n",
        "\n",
        "    return kp, desc\n",
        "\n",
        "  #Descriptor를 비교하여 매치 상태가 좋은 점들만 리턴\n",
        "  def findGoodMatch(self, desc1, desc2, \\\n",
        "                     matcher_type = 'FLANN', \\\n",
        "                     best_match_count = 2, \\\n",
        "                     match_dist = 0.7): \n",
        "    matches = self.matcher.knnMatch(desc1,desc2,k=best_match_count)\n",
        "\n",
        "    good = []\n",
        "    for m_n in matches:\n",
        "      if len(m_n) != 2:\n",
        "        continue\n",
        "      (m,n) = m_n\n",
        "      if m.distance < match_dist *n.distance:\n",
        "          good.append(m)\n",
        "    return good"
      ],
      "metadata": {
        "id": "o8p9FitPrGlM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#드라이브안에서 프로젝트 드라이브로 이동\n",
        "root_path = '/content/drive/MyDrive/SandBox/Stitch'\n",
        "\n",
        "os.chdir(root_path);\n",
        "\n",
        "!pwd\n",
        "\n",
        "source = cv2.imread('staringNight.png')\n",
        "\n",
        "frameGen = FrameGenerator(source, 300, 300)\n",
        "h,w = source.shape[:2]\n",
        "fs = FrameStitcher(w,h)\n",
        "fs.setFrame(frameGen.generate())\n"
      ],
      "metadata": {
        "id": "6Hlrn32BUtTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sourceframe = None\n",
        "outputframe = None\n",
        "outputlock = threading.Lock()\n",
        "sourcelock = threading.Lock()\n",
        "#vs = VideoStream(src=0).start()\n",
        "\n",
        "def generate_frame():\n",
        "  global outputframe, sourceframe,  outputlock, sourcelock\n",
        "\n",
        "  i = 0;\n",
        "  while True:\n",
        "    #다른 사진으로 프레임 변경\n",
        "    source = frameGen.generate()\n",
        "    frame = fs.setFrame(source)\n",
        "\n",
        "    with sourcelock:\n",
        "      sourceframe = source.copy()\n",
        "\n",
        "    with outputlock:\n",
        "      outputframe = frame.copy()\n",
        "    #FPS를 1로\n",
        "    time.sleep(1)\n",
        "    "
      ],
      "metadata": {
        "id": "UgsbKkd6r72t"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateOutput():\n",
        "  global outputframe, outputlock\n",
        "\n",
        "  while True:\n",
        "    with outputlock:\n",
        "      if outputframe is None:\n",
        "        continue\n",
        "\n",
        "      (flag, encodedImage) = cv2.imencode(\".jpg\", outputframe)\n",
        "      outputframe = None\n",
        "\n",
        "      if flag is None:\n",
        "        continue\n",
        "\n",
        "    yield(b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' +\n",
        "\t\t\t  bytearray(encodedImage) + b'\\r\\n')"
      ],
      "metadata": {
        "id": "IKqbb6R3traC"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateSource():\n",
        "  global sourceframe, sourcelock\n",
        "\n",
        "  while True:\n",
        "    with sourcelock:\n",
        "      if sourceframe is None:\n",
        "        continue\n",
        "\n",
        "      (flag, encodedImage) = cv2.imencode(\".jpg\", sourceframe)\n",
        "      sourceframe = None\n",
        "\n",
        "      if flag is None:\n",
        "        continue\n",
        "\n",
        "    yield(b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' +\n",
        "\t\t\t  bytearray(encodedImage) + b'\\r\\n')"
      ],
      "metadata": {
        "id": "lpaUh4ybsulQ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.responses import StreamingResponse, HTMLResponse"
      ],
      "metadata": {
        "id": "rI0ha_s4U5Z9"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI(title='Opencv Streaming')\n",
        "\n",
        "@app.get(\"/\",response_class=HTMLResponse)\n",
        "async def home():\n",
        "  return \"\"\"\n",
        "  <html>\n",
        "  <head>\n",
        "    <title>Image Files Streaming</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <h1>Image File Streaming</h1>\n",
        "    <img src=\"/video_source\">\n",
        "    <img src=\"/video_pano\" height=\"600\" width=\"800\">\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.get(\"/video_source\")\n",
        "def video_source():\n",
        "\t# return the response generated along with the specific media\n",
        "\t# type (media_type)\n",
        "\treturn StreamingResponse(generateSource(),media_type=\"multipart/x-mixed-replace;boundary=frame\")\n",
        " \n",
        "@app.get(\"/video_pano\")\n",
        "def video_pano():\n",
        "\t# return the response generated along with the specific media\n",
        "\t# type (media_type)\n",
        "\treturn StreamingResponse(generateOutput(),media_type=\"multipart/x-mixed-replace;boundary=frame\")"
      ],
      "metadata": {
        "id": "b5ApkUXfVKk5"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start frame generate thread\n",
        "t = threading.Thread(target=generate_frame,args=())\n",
        "t.daemon = True\n",
        "t.start()"
      ],
      "metadata": {
        "id": "VTuimAZj1I7p",
        "outputId": "861be89e-073e-40b7-deaf-23d6b644a0b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Allows the server to be run in this interactive environment\n",
        "#nest_asyncio.apply()\n",
        "\n",
        "# Host depends on the setup you selected (docker or virtual env)\n",
        "#host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n",
        "\n",
        "# Spin up the server!    \n",
        "#uvicorn.run(app, host=host, port=8000)\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "id": "lteqMRM1xd_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}