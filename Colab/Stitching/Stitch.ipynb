{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0HzwU630GTWUA2VlSa7tQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miragecore/SandBox/blob/devel/Colab/Stitching/Stitch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "특징점 추출 + 파노라마 생성까지 목표로!!\n",
        "\n",
        "\n",
        "참조 1  \n",
        "https://bkshin.tistory.com/entry/OpenCV-29-%EC%98%AC%EB%B0%94%EB%A5%B8-%EB%A7%A4%EC%B9%AD%EC%A0%90-%EC%B0%BE%EA%B8%B0?category=1148027\n",
        "\n",
        "이 분이 정리해둔 걸 그저 Colab으로 가져왔다. 감사합니다.\n",
        "\n",
        "참조 2  \n",
        "https://stackoverflow.com/questions/64659657/fast-and-robust-image-stitching-algorithm-for-many-images-in-python"
      ],
      "metadata": {
        "id": "clEVooYDGVAi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GE3_wbnFlClL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4a3847-bba7-421f-c8e7-9762efa33a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os;\n",
        "root_path = '/content/drive/MyDrive/SandBox/Stitch/Baegot'\n",
        "\n",
        "os.chdir(root_path);\n",
        "\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "tn5MTbOllDlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572757eb-0295-46c9-eaae-becf9a854087"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SandBox/Stitch/Baegot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display"
      ],
      "metadata": {
        "id": "CpXg32JnC8Zj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some example images\n",
        "image_files = [\n",
        "    'Pic1.jpg',\n",
        "    'Pic2.jpg'\n",
        "]\n",
        "\n",
        "for image_file in image_files:\n",
        "    print(f\"\\nDisplaying image: {image_file}\")\n",
        "    display(Image(filename=f\"{image_file}\"))"
      ],
      "metadata": {
        "id": "1GYRIVoPC8_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab에서 cv2.imshow는 사용할 수 없단다.  \n",
        "대신   \n",
        "from google.colab.patches import cv2_imshow.   \n",
        "cv2_imshow(<image>)  \n",
        "를 사용한다."
      ],
      "metadata": {
        "id": "6dHduXxoF3ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, numpy as np\n",
        "#\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img1 = cv2.imread(image_files[0])\n",
        "img2 = cv2.imread(image_files[1])\n",
        "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "detector = cv2.ORB_create()\n",
        "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
        "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
        "\n",
        "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "matches = matcher.match(desc1, desc2)\n",
        "\n",
        "# 매칭 결과를 거리기준 오름차순으로 정렬 ---③\n",
        "matches = sorted(matches, key=lambda x:x.distance)\n",
        "# 최소 거리 값과 최대 거리 값 확보 ---④\n",
        "min_dist, max_dist = matches[0].distance, matches[-1].distance\n",
        "# 최소 거리의 15% 지점을 임계점으로 설정 ---⑤\n",
        "ratio = 0.2\n",
        "good_thresh = (max_dist - min_dist) * ratio + min_dist\n",
        "# 임계점 보다 작은 매칭점만 좋은 매칭점으로 분류 ---⑥\n",
        "good_matches = [m for m in matches if m.distance < good_thresh]\n",
        "print('matches:%d/%d, min:%.2f, max:%.2f, thresh:%.2f' \\\n",
        "        %(len(good_matches),len(matches), min_dist, max_dist, good_thresh))\n",
        "# 좋은 매칭점만 그리기 ---⑦\n",
        "res = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, \\\n",
        "                flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
        "# 결과 출력\n",
        "#cv2.imshow('Good Match', res)\n",
        "cv2_imshow(res)\n",
        "#cv2.waitKey()\n",
        "#cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "prMdI-x_DEKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
        "matches = matcher.knnMatch(desc1, desc2, 2)\n",
        "\n",
        "# 첫번재 이웃의 거리가 두 번째 이웃 거리의 75% 이내인 것만 추출---⑤\n",
        "ratio = 0.75\n",
        "good_matches = [first for first,second in matches \\\n",
        "                    if first.distance < second.distance * ratio]\n",
        "print('matches:%d/%d' %(len(good_matches),len(matches)))\n",
        "\n",
        "# 좋은 매칭만 그리기\n",
        "res = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, \\\n",
        "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
        "# 결과 출력                    \n",
        "cv2_imshow(res)"
      ],
      "metadata": {
        "id": "NmFZc2pbE6_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 좋은 매칭점의 queryIdx로 원본 영상의 좌표 구하기 ---③\n",
        "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ])\n",
        "# 좋은 매칭점의 trainIdx로 대상 영상의 좌표 구하기 ---④\n",
        "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ])\n",
        "# 원근 변환 행렬 구하기 ---⑤\n",
        "mtrx, mask = cv2.findHomography(src_pts, dst_pts, )\n",
        "# 원본 영상 크기로 변환 영역 좌표 생성 ---⑥\n",
        "h,w, = img1.shape[:2]\n",
        "pts = np.float32([ [[0,0]],[[0,h-1]],[[w-1,h-1]],[[w-1,0]] ])\n",
        "# 원본 영상 좌표를 원근 변환  ---⑦\n",
        "dst = cv2.perspectiveTransform(pts,mtrx)\n",
        "# 변환 좌표 영역을 대상 영상에 그리기 ---⑧\n",
        "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
        "\n",
        "# 좋은 매칭 그려서 출력 ---⑨\n",
        "res = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, \\\n",
        "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "cv2_imshow(res)"
      ],
      "metadata": {
        "id": "5AH5CNNWG3jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JIXd3DkoJPsF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}