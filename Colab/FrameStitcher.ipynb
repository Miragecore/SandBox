{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQ63qcdCXudQBwBx42qJR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miragecore/SandBox/blob/main/Colab/FrameStitcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMVlXJbcbHhF"
      },
      "outputs": [],
      "source": [
        "Frame을 받아서 개별 프레임다위마다 스티칭을 하는 클래스 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-5l9XkPbNIQ",
        "outputId": "9737f44d-5410-4547-8808-f2497b92061e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#드라이브안에서 프로젝트 드라이브로 이동\n",
        "import os;\n",
        "root_path = '/content/drive/MyDrive/SandBox/Stitch/earring'\n",
        "\n",
        "os.chdir(root_path);\n",
        "\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ3J-EN9bNA_",
        "outputId": "655b60b3-3e7f-4140-e272-7a9fa170cebe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SandBox/Stitch/earring\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from IPython.display import Image, display\n",
        "import cv2, numpy as np\n",
        "\n",
        "#Colab에서 imShow를 사용하기 위해 cv2_imshow를 사용한다.\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import math\n",
        "\n",
        "#속도 관련 ORB 사용\n",
        "#SIFT or SURF는 4.3이상의 버전에서만 사용가능하다. \n",
        "#if cv2.__version__ != \"4.4.0\":\n",
        "#  print(cv2.__version__)\n",
        "  #설치후에는 런타임을 재시작해줘야 한다.\n",
        "#  !pip install opencv-contrib-python==4.4.0.44"
      ],
      "metadata": {
        "id": "Ahr11dxxbM59"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#먼저 업로드해둔 이미지 파일들\n",
        "image_files = [\n",
        "    'earring_1.jpg',\n",
        "    'earring_2.jpg',\n",
        "    'earring_3.jpg']\n",
        "\n",
        "img1 = cv2.imread(image_files[0])\n",
        "img2 = cv2.imread(image_files[1])\n",
        "img3 = cv2.imread(image_files[2])"
      ],
      "metadata": {
        "id": "vGTN8_uJDsER"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image의 외곽 좌표를 np.array로 리턴\n",
        "def getImageCorner(img):\n",
        "  h, w = img.shape[:2]\n",
        "  return np.float32([ [0,0],[0,h],[w,h],[w,0]])"
      ],
      "metadata": {
        "id": "6am5VzSgbxfB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 이미지의 그레이 이미지 복사본을 리턴\n",
        "def getGrayImage(img):\n",
        "  if len(img.shape) > 2:\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  else :\n",
        "    return img.copy()"
      ],
      "metadata": {
        "id": "fBvC7xAvbvag"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dst의 roi 영역에 src 이미지를 설정\n",
        "def copyImageROI(src, dst, x, y):\n",
        "  h,w = src.shape[:2]\n",
        "  #assert dst.shape[0] < y+h, \"src size error\"\n",
        "  #assert dst.shape[1] < x+w, \"src size error\"\n",
        "\n",
        "  dst[y:y+h, x: x+w] = src"
      ],
      "metadata": {
        "id": "Y2pujuhPrJuJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTfCorner(c1, c2):\n",
        "  corner = np.concatenate((c1, c2), axis=0)\n",
        "  [xmin, ymin] = np.int32(corner.min(axis=0).ravel() - 0.5)\n",
        "  [xmax, ymax] = np.int32(corner.max(axis=0).ravel() + 0.5)\n",
        "  return xmin, xmax, ymin, ymax"
      ],
      "metadata": {
        "id": "Cu_EtA1CqCyM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FrameStitcher:\n",
        "  def __init__(self, w, h):\n",
        "    #ORB Dector init   \n",
        "    self.detector= cv2.ORB_create()\n",
        "\n",
        "    #FLANN Matcher init\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "    search_params = dict(checks = 50)\n",
        "    self.matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    #최종 ROI 좌표\n",
        "    self.current_roi = []\n",
        "    \n",
        "    #최소 매칭 수\n",
        "    self.MIN_MATCH_COUNT = 4\n",
        "\n",
        "    #현재 프레임 카운트\n",
        "    self.frame_count = 0\n",
        "\n",
        "    #최종 결과 이미지의 크기 설정 및 초기화\n",
        "    self.output_frame_w = w\n",
        "    self.output_frame_h = h\n",
        "    self.outputframe = np.zeros((h,w,3), np.uint8)\n",
        "    self.outputmask = None\n",
        "\n",
        "    #변환 변수들 0 초기화\n",
        "    #입력 프레임 크기\n",
        "    self.frame_w = 0\n",
        "    self.frame_h = 0\n",
        "\n",
        "    #입력 프레임 코너 좌표\n",
        "    self.frame_corner = []\n",
        "    \n",
        "    #마지막 변환 매트릭스\n",
        "    self.M = np.array([[1,0,0], [0,1,0], [0,0,1]],np.float32)\n",
        "\n",
        "    #마지막 프레임 keypoint, descriptor\n",
        "    self.kp = None\n",
        "    self.desc = None\n",
        "\n",
        "  def initFirstFrame(self, frame):\n",
        "    #카메라 프레임은 항상 동일한 크기로 가정\n",
        "    self.frame_h, self.frame_w = frame.shape[:2]\n",
        "    #동일한 영상이면 매 프레임마다 최외곽 좌표도 동일함\n",
        "    self.frame_corner = getImageCorner(frame).reshape(-1,1,2)\n",
        "    \n",
        "    #화면 중앙으로 보내기 위한 변환 매트릭스 생성\n",
        "    tx = math.floor(self.output_frame_w /2 - self.frame_w /2)\n",
        "    ty = math.floor(self.output_frame_h/2 - self.frame_h /2)\n",
        "    self.M = np.array([[1,0,tx],[0,1,ty],[0,0,1]],np.float32)\n",
        "    \n",
        "    self.kp, self.desc = self.findFeature(frame)\n",
        "\n",
        "    #평행이동이라 계산 불필요\n",
        "    #img1_tf_corner = cv2.perspectiveTransform(self.frame_corner, self.M)\n",
        "    #초기 변환으로 첫 프레임을 결과 영상 센터로 이동 \n",
        "    #tmp_frame = cv2.warpPerspective(frame,self.M,(self.frame_w, self.frame_h))\n",
        "\n",
        "    #출력 프레임 roi에 이미지 설정\n",
        "    copyImageROI(frame, self.outputframe, tx,ty)\n",
        "    #초기 출력 영역 마스크 생성\n",
        "    _, self.outputmask = cv2.threshold(self.outputframe, 0, 255, \\\n",
        "                                       cv2.THRESH_BINARY)\n",
        "    \n",
        "    #outputframe에서 마지막 추가된 프레임만의 영역\n",
        "    self.current_roi = [tx, ty, self.frame_w, self.frame_h]\n",
        "    self.frame_count += 1\n",
        "    \n",
        "  def setFrame(self, frame):\n",
        "    #한번 실행되고 매번 검사하는 것은 고민해볼 문제\n",
        "    if self.frame_count == 0:\n",
        "      self.initFirstFrame(frame)\n",
        "\n",
        "    kp1, desc1 = self.findFeature(frame)\n",
        "    good = self.findGoodMatch(desc1, self.desc)\n",
        "\n",
        "    if len(good) < self.MIN_MATCH_COUNT:\n",
        "      return self.outputframe\n",
        "\n",
        "    src_pts = np.float32([ self.kp[m.queryIdx].pt for m in good ])\\\n",
        "    .reshape(-1,1,2)\n",
        "    dst_pts = np.float32([ kp1[m.trainIdx].pt for m in good ])\\\n",
        "    .reshape(-1,1,2)\n",
        "\n",
        "    #frame을 outputframe으로 변환 할 것이기 때문에\n",
        "    tM, RANSAC_mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC,5.0)\n",
        "\n",
        "    #외곽 좌표 변환\n",
        "    corner = getImageCorner(frame)\n",
        "    frame_tf_corner = cv2.perspectiveTransform(corner,tM)\n",
        "    xmax, xmin, ymax, ymin = getTfCorner(self.frame_corner,frame_tf_corner)\n",
        "\n",
        "    #새로운 ROI 설정\n",
        "    roix = tx + xmin\n",
        "    roiy = ty + ymin\n",
        "    roiw = xmax - xmin\n",
        "    roih = ymax - ymin\n",
        "    source_roi = self.outputframe[roiy:roiy+roih, roix:roix+roiw]\n",
        "\n",
        "    #변환 결과 영상 크기 \n",
        "    warp_img = cv2.warpPerspective(frame,tM,(roiw, roih))\n",
        "    _, warp_mask = cv2.threshold(warp_img, 0, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    ### 새로운 이미지 전체가 반영되도록 병합\n",
        "    warp_mask_inv = cv2.bitwise_not(warp_mask)\n",
        "\n",
        "    masked_fg = cv2.bitwise_and(warp_img, warp_img, mask=mask)\n",
        "    masked_bg = cv2.bitwise_and(source_roi, source_roi, mask=mask_inv)\n",
        "    added = masked_fg + masked_bg\n",
        "    self.outputframe[roiy:roiy+roih, roix:roix+roiw] = added\n",
        "\n",
        "    #마지막 프레임 keypoint & descriptor update\n",
        "    self.last_frame = frame\n",
        "    self.kp = kp1\n",
        "    self.desc = desc1\n",
        "    self.frame_count += 1\n",
        "\n",
        "  #2장의 이미지를 입력 받아서 keypoint와 변환 매트릭스를 리턴\n",
        "  def findFeature(self, img,detector_type = 'SIFT', mask_enable=False,\\\n",
        "                min_match_count = 10):\n",
        "    #흑백 이미지 생성\n",
        "    img_gray = getGrayImage(img)\n",
        "\n",
        "    #이미지에서 0인 영역으로 마스크를 생성시켜 계산의 속도 향상, \n",
        "    #검은 영역이 없다면 무쓸모\n",
        "    mask = None\n",
        "    if(mask_enable):\n",
        "      _, mask = cv2.threshold(img_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "    \n",
        "    #keypoint와 Descriptor 찾기\n",
        "    kp, desc = self.detector.detectAndCompute(img, mask)\n",
        "\n",
        "    return kp, desc\n",
        "\n",
        "  #Descriptor를 비교하여 매치 상태가 좋은 점들만 리턴\n",
        "  def findGoodMatch(self, desc1, desc2, \\\n",
        "                     matcher_type = 'FLANN', \\\n",
        "                     best_match_count = 2, \\\n",
        "                     match_dist = 0.7): \n",
        "    matches = self.matcher.knnMatch(desc1,desc2,best_match_count)\n",
        "\n",
        "    # 2번째 후보와 거리가 0.7 이상인 포인트를 좋은 매치로 분류\n",
        "    good = []\n",
        "    for m,n in matches:\n",
        "        if m.distance < match_dist *n.distance:\n",
        "            good.append(m)\n",
        "\n",
        "    return good\n"
      ],
      "metadata": {
        "id": "tWGVRyDgbYsq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs = FrameStitcher(1000,1000)\n",
        "fs.initFirstFrame(img1)\n",
        "fs.setFrame(img2)\n",
        "\n",
        "cv2_imshow(fs.outputframe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "dFHqweqIDe2D",
        "outputId": "dfe42a22-1b3e-4ded-f6fd-c24aab8c08a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-966e96baca41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameStitcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitFirstFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-cbce72ee6dd3>\u001b[0m in \u001b[0;36msetFrame\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mgood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindGoodMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_MATCH_COUNT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-cbce72ee6dd3>\u001b[0m in \u001b[0;36mfindGoodMatch\u001b[0;34m(self, desc1, desc2, matcher_type, best_match_count, match_dist)\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;31m#Descriptor를 비교하여 매치 상태가 좋은 점들만 리턴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfindGoodMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc2\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0mmatcher_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FLANN'\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0mbest_match_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0mmatch_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdesc2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_match_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# 2번째 후보와 거리가 0.7 이상인 포인트를 좋은 매치로 분류\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/flann/src/miniflann.cpp:315: error: (-210:Unsupported format or combination of formats) in function 'buildIndex_'\n> type=0\n> "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I61Q4KOsEQuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}